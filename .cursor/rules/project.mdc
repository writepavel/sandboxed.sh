---
description: Core Open Agent architecture - SimpleAgent system with full machine access
alwaysApply: true
---

# Open Agent

Minimal autonomous coding agent in Rust with **full machine access** (not sandboxed).

## Quick Reference

| Component | Location | Purpose |
|-----------|----------|---------|
| Backend (Rust) | `src/` | HTTP API + agent system |
| Dashboard (Next.js) | `dashboard/` | Web UI (Bun, not npm) |
| iOS Dashboard | `ios_dashboard/` | Native iOS app (Swift/SwiftUI) |
| MCP configs | `.open_agent/mcp/config.json` | Model Context Protocol servers |
| Tuning | `.open_agent/tuning.json` | Calibration data |

## Architecture

```
SimpleAgent
    └── TaskExecutor → runs tools in a loop with auto-upgrade
```

The agent system was simplified from a complex hierarchical orchestrator to a single `SimpleAgent` that:
- Automatically upgrades outdated model names via `ModelResolver`
- Uses `TaskExecutor` for tool-based execution
- Supports model overrides per mission/message
- Handles parallel mission execution

### Module Map

```
src/
├── agents/           # Agent system
│   ├── simple.rs     # SimpleAgent (main entry point)
│   └── leaf/         # TaskExecutor
├── budget/           # Cost tracking, pricing, smart retry
│   ├── benchmarks.rs # Model capability scores from llm-stats.com
│   ├── pricing.rs    # OpenRouter pricing + model allowlist
│   └── resolver.rs   # Model family auto-upgrade system
├── memory/           # Supabase + pgvector persistence + context building
│   ├── supabase.rs   # Database client
│   ├── context.rs    # ContextBuilder, SessionContext, MemoryContext
│   ├── retriever.rs  # Semantic search
│   └── writer.rs     # Event recording
├── mcp/              # MCP server registry + config
├── llm/              # OpenRouter client
├── tools/            # File ops, terminal, git, web, search, desktop, storage, memory
├── task/             # Task types + verification
├── config.rs         # Config, MemoryConfig, ContextConfig
└── api/              # HTTP routes (axum)
```

## Agent Rules

1. **Full system access**: Can read/write any file, execute any command, search anywhere
2. **Working directory**: `WORKING_DIR` env (default: `/root` prod, `.` dev) - paths can be relative or absolute
3. **Directory structure** (production):
   - `/root/context/` - user uploads (dashboard file explorer)
   - `/root/work/` - agent working area (subfolders per task)
   - `/root/tools/` - reusable scripts (auto-discovered by TaskExecutor)

## API Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `POST` | `/api/task` | Submit task |
| `GET` | `/api/task/{id}` | Get status |
| `GET` | `/api/task/{id}/stream` | SSE progress |
| `GET` | `/api/health` | Health check |
| `GET` | `/api/runs` | List archived runs |
| `GET/POST/DELETE` | `/api/mcp/*` | MCP management |
| `GET` | `/api/models` | List available models |
| `GET` | `/api/models/families` | List model families |
| `GET` | `/api/models/performance` | Get learned model stats |
| `POST` | `/api/models/refresh` | Reload model data |

### Control Session Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `POST` | `/api/control/message` | Send message to agent |
| `POST` | `/api/control/tool_result` | Submit frontend tool result |
| `GET` | `/api/control/stream` | SSE event stream |
| `POST` | `/api/control/cancel` | Cancel current execution |
| `GET` | `/api/control/tree` | Get agent tree snapshot (refresh resilience) |
| `GET` | `/api/control/progress` | Get execution progress ("Subtask X/Y") |

### Mission Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `GET` | `/api/control/missions` | List all missions |
| `POST` | `/api/control/missions` | Create new mission (optional: title, model_override) |
| `GET` | `/api/control/missions/current` | Get current active mission |
| `GET` | `/api/control/missions/:id` | Get specific mission |
| `GET` | `/api/control/missions/:id/tree` | Get mission's agent tree |
| `POST` | `/api/control/missions/:id/load` | Switch to mission |
| `POST` | `/api/control/missions/:id/status` | Set mission status |
| `POST` | `/api/control/missions/:id/cancel` | Cancel specific mission |
| `POST` | `/api/control/missions/:id/resume` | Resume interrupted mission |
| `POST` | `/api/control/missions/:id/parallel` | Start mission in parallel |

### Parallel Execution Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `GET` | `/api/control/running` | List running missions |
| `GET` | `/api/control/parallel/config` | Get parallel execution config |

### Mission Statuses

Missions can be in one of these states:
- `active` - Currently being worked on
- `completed` - Successfully finished
- `failed` - Failed with errors
- `interrupted` - Stopped due to server shutdown/cancellation (resumable)
- `blocked` - Blocked by external factors (resumable)
- `not_feasible` - Cannot be completed as specified

## Model Selection (U-Curve)

- **Cheap models**: low token cost, high failure rate, more retries
- **Expensive models**: high token cost, low failure rate
- **Optimal**: minimizes `E[total_cost] = Σ P(retry_n) × cost_n`

Default ladder: `google/gemini-3-flash-preview` → `qwen/qwen3-235b-a22b-instruct` → `deepseek/deepseek-v3.2`

### Model Preferences

**NEVER use Claude models** (anthropic/claude-*) - they are prohibitively expensive.

**Preferred models (in order):**
1. `google/gemini-3-flash-preview` - Fast, cheap, excellent tool use, **default**
2. `qwen/qwen3-235b-a22b-instruct` - Strong reasoning, affordable
3. `deepseek/deepseek-v3.2` - Good value, capable
4. `x-ai/grok-4.1-fast` - Fast alternative
5. `qwen/qwen3-next-80b-a3b-thinking` - Good for complex reasoning

When implementing model selection or defaults, always prefer these models over Claude.

## Model Family System

The agent automatically upgrades outdated model names to the latest versions. This prevents issues where training data suggests old model names like `gemini-1.5-flash` instead of the newer `gemini-3-flash-preview`.

### How It Works

1. **Model Families**: Models are grouped into families (e.g., `gemini-flash`, `gpt-4`, `deepseek`)
2. **Auto-Upgrade**: When an old model is requested, it's resolved to the latest in its family
3. **Aliases**: Common aliases like "sonnet" or "gpt4" resolve to the latest

### Model Data Sources

| File | Purpose | Updated By |
|------|---------|------------|
| `models_with_benchmarks.json` | Families, aliases, benchmark scores | `scripts/merge_benchmarks.py` |
| `src/budget/pricing.rs` | Model allowlist (CAPABLE_MODEL_BASES) | Manual (keep in sync) |

### Model Tiers

| Tier | Examples | Use Case |
|------|----------|----------|
| **flagship** | deepseek-r1, o1, qwen3-235b | Complex reasoning, important tasks |
| **mid** | gemini-3-flash, deepseek-v3.2, grok-4.1 | Default for most tasks |
| **fast** | gpt-4.1-mini, gemini-flash | Quick, cheap tasks |

> ⚠️ **Cost Warning**: Never use Claude models (anthropic/*) - they are 10-50x more expensive than alternatives with similar capability.

### API Endpoints

| Method | Path | Purpose |
|--------|------|---------|
| `GET` | `/api/models` | List available models |
| `GET` | `/api/models/families` | List model families |
| `POST` | `/api/models/refresh` | Reload model data from disk |

### Updating Model Data

```bash
# Regenerate models_with_benchmarks.json with latest from OpenRouter + benchmarks
python scripts/merge_benchmarks.py

# Then update CAPABLE_MODEL_BASES in src/budget/pricing.rs if needed
# And call POST /api/models/refresh to reload without restart
```

## Smart Retry

Analyzes failure signals to decide action:

| Failure Mode | Signals | Action |
|--------------|---------|--------|
| Capability insufficient | stuck in loops, repetitive | **Upgrade** model |
| Budget exhausted + progress | files modified, high tool success | **Continue** or cheaper |
| External error | API/network issues | **Retry** same config |
| Infeasible | consistent failures | **Stop** |

## Desktop Automation

When `DESKTOP_ENABLED=true`, the agent has access to desktop automation tools:

| Tool | Purpose |
|------|---------|
| `desktop_start_session` | Start Xvfb + i3 virtual desktop |
| `desktop_stop_session` | Clean up desktop session |
| `desktop_screenshot` | Capture screen (returns PNG path) |
| `desktop_type` | Type text or send key combos |
| `desktop_click` | Mouse click at coordinates |
| `desktop_get_text` | Extract text via AT-SPI or OCR |
| `desktop_mouse_move` | Move mouse without clicking |
| `desktop_scroll` | Scroll wheel at position |

Setup: See `docs/DESKTOP_SETUP.md` and run `scripts/install_desktop.sh` on server.

## Image Sharing

The agent can share images in markdown using the `upload_image` tool:

| Tool | Purpose |
|------|---------|
| `upload_image` | Upload local image to Supabase Storage, returns public URL |

**Usage:**
1. Take a screenshot or create an image file
2. Use `upload_image` with the file path
3. Include the returned markdown `![description](url)` in your response

**Supabase Storage:**
- Bucket: `images` (public, created in Supabase dashboard)
- Public URL format: `https://<project>.supabase.co/storage/v1/object/public/images/<file>`
- Supported formats: PNG, JPEG, GIF, WebP, SVG

## Memory System

The agent has a layered memory system inspired by ChatGPT's architecture:

### Memory Layers

| Layer | Description | Injection |
|-------|-------------|-----------|
| **Session Metadata** | Time, working dir, context files | Every system prompt |
| **User Facts** | Stored preferences and project info | Every system prompt (configurable) |
| **Mission Summaries** | Past mission learnings with embeddings | Every system prompt (configurable) |
| **Task Chunks** | Semantic search over past task outputs | On-demand via RAG |

### Memory Tools

| Tool | Purpose |
|------|---------|
| `search_memory` | Search past tasks, missions, and facts |
| `store_fact` | Store user preferences or project info |

### Database Tables

Required tables in Supabase (see `docs/MEMORY_TABLES.sql`):
- `user_facts` - Long-term user/project facts with embeddings
- `mission_summaries` - Learnings from completed missions

## Context System

Context injection is managed by `ContextBuilder` (`src/memory/context.rs`) with centralized configuration.

### ContextConfig (`src/config.rs`)

All context-related limits are configurable via environment variables:

| Setting | Env Var | Default | Description |
|---------|---------|---------|-------------|
| History messages | `CONTEXT_MAX_HISTORY_MESSAGES` | 10 | Max conversation messages to include |
| Message chars | `CONTEXT_MAX_MESSAGE_CHARS` | 5000 | Max chars per message |
| History total | `CONTEXT_MAX_HISTORY_CHARS` | 30000 | Total history context limit |
| Memory chunks | `CONTEXT_MEMORY_CHUNK_LIMIT` | 3 | Relevant past chunks to retrieve |
| Chunk threshold | `CONTEXT_MEMORY_THRESHOLD` | 0.6 | Similarity threshold (0-1) |
| User facts | `CONTEXT_USER_FACTS_LIMIT` | 10 | User facts to inject |
| Mission summaries | `CONTEXT_MISSION_SUMMARIES_LIMIT` | 5 | Recent summaries to inject |
| Tool results | `CONTEXT_MAX_TOOL_RESULT_CHARS` | 15000 | Tool output truncation limit |

### Context Components

The `ContextBuilder` produces three structured context types:

```rust
// Session context (sync)
SessionContext { time, working_dir, context_files, mission_title }

// Memory context (async, requires DB)
MemoryContext { past_experience, user_facts, mission_summaries }

// History context (sync)
String (formatted conversation history)
```

### Automatic Context Injection

The `TaskExecutor` automatically injects:
1. **Session metadata** (time, working directory, context files)
2. **Relevant past task chunks** (via semantic search)
3. **User facts** (preferences, conventions)
4. **Recent mission summaries**

This allows the agent to learn from past experience without explicit prompting.

### Directory Structure

Context paths are derived from `ContextConfig`:
- `context/` - User uploads (read by session metadata)
- `work/` - Agent workspace
- `tools/` - Reusable scripts

## After Significant Changes

When you make architectural changes to this codebase, **update the Cursor rules**:
- New module → add to module map
- New API endpoint → add to endpoints table
- New env var → add to `secrets.mdc`
- New agent type → update architecture diagram
